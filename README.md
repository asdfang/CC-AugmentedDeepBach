# DeepBach
The DeepBach augmentative generation project is described [here](https://alisawuffles.github.io/project/deepbach/).

The code uses python 3.6 together with [PyTorch v1.0](https://pytorch.org/) and
 [music21](http://web.mit.edu/music21/) libraries.

## Usage
Every time we run `deepBach.py`, there are three things we can do: (1) load a model (no `--train` or `--update` flag) for generation, (2) train a model (include `--train` flag), (3) update a trained model (include `--update` flag). A model can be trained and updated in one run by including both corresponding flags.

```
Usage: deepBach.py [OPTIONS]

Options:
(general)
  --train                           train or retrain the specified model
  --update                          update the specified model
  --model_id INTEGER                ID of the model to load, train, and/or update
  --include_transpositions          whether to include transpositions when training a model/
                                    whether the trained model includes transpositions when updating or generating

(model hyperparameters)
  --note_embedding_dim INTEGER      size of the note embeddings
  --meta_embedding_dim INTEGER      size of the metadata embeddings
  --num_layers INTEGER              number of layers of the LSTMs
  --lstm_hidden_size INTEGER        hidden size of the LSTMs
  --dropout_lstm FLOAT              amount of dropout between LSTM layers
  --linear_hidden_size INTEGER      hidden size of the Linear layers
  --batch_size INTEGER              training batch size
  --num_epochs INTEGER              number of training epochs

(update parameters)
  --update_iterations               number of generation-update iterations
  --generations_per_iteration       number of chorales to generate at each iteration

(generation parameters)
  --num_generations                 number of generations for inspection
  --num_iterations INTEGER          number of parallel pseudo-Gibbs sampling iterations
  --sequence_length_ticks INTEGER   length of the generated chorale (in ticks)
```

## Experimental pipeline
This section describes the experiments we performed.
### Training
We train two models: (1) a model trained on the original chorales and their transpositions, which is the setting equivalent to the original DeepBach paper, and (2) a model without transpositions, which serves as our base model. The saved model has the lowest validation loss. After training each model, we also generate `100` chorales, which will be useful later for evaluation. These are saved as MIDI files in `generations/[MODEL_ID]/`, and its scores are recorded in a spreadsheet at `data/model[MODEL_ID]_scores.csv`/

Train model with transpositions. The `--include_transpositions` flag will ensure that we train on the correct dataset.
```
python deepBach.py --train --include_transpositions --model_id=10
```

Train base model without transpositions.
```
python deepBach.py --train --model_id=11
```
Now we want to update the base model. First, copy the base model into a new directory so that we do not overwrite it.
```
cp -r 11 12
```
Now we update the base model. Specify `update_iterations` and `generations_per_iteration`. 
```
python deepBach.py --model_id=12 --update --update_iterations=50 --generations_per_iteration=50
```
### Evaluation
In our experiments we first evaluate the score function, and then the quality of the chorales generated by the model trained through augmentative generation.
#### Evaluating the score function
There are many useful functions in `visualize_score_dist.py`. One sanity check is that real Bach chorales should score more highly than generated chorales. The function `plot_distributions()` will plot the score distribution of these two categories of chorales as both histograms and boxplots, provided a path to the corresponding csv files. 

The function `plot_score_per_iteration()` plots the score distribution at each iteration. The hope is that the mean of the score distribution will shift upwards as training goes on.

#### Human paired discrimination
For human evaluation, we create many pairs of chorales where on chorale is real and one is generated. The generated output comes from one of model `10` (original DeepBach), `11` (base model), `12` (updated model). These generations are retrieved randomly from the folder corresponding to each model, so make sure those are generations from the model you want to test! If not, it might be safe to delete those generations and recreate them with
```
python deepBach.py --model_id=[MODEL_ID] --num_generations=100
```

To set up the experiment, we will create folders containing pairs of chorales. 
```
python experiments/paired_evaluation.py
```

